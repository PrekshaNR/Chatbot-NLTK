{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2fbbd95f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\user\\anaconda3\\envs\\chatbot\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy>=1.22.4 in c:\\users\\user\\anaconda3\\envs\\chatbot\\lib\\site-packages (from pandas) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\anaconda3\\envs\\chatbot\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\anaconda3\\envs\\chatbot\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\user\\anaconda3\\envs\\chatbot\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\anaconda3\\envs\\chatbot\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords,wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from difflib import get_close_matches\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7edf6785",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "packages = ['punkt_tab','wordnet','stopwords','omw-1.4','averaged_perceptron_tagger_eng']\n",
    "for pkg in packages:\n",
    "    try:\n",
    "        nltk.data.find(pkg)\n",
    "    except Exception:\n",
    "        nltk.download(pkg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "470fb597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample dataset\n",
    "texts = [\n",
    "    \"Hi! Are you open today?   \",\n",
    "    \"Do you have chesecake?\",\n",
    "    \"I don't want spicy food, do you have mild options?\",\n",
    "    \"Can I reserve a table for 2 at 7pm?\",\n",
    "    \"Is the trufle pasta available?\",\n",
    "    \"   What's your addresses?   \",\n",
    "    \"I'm looking for pizzas and pastas.\",\n",
    "    \"The desserts were amazing yesterday!\",\n",
    "    \"The customer is running late.\",\n",
    "    \"We are better than the other restaurant.\"\n",
    "]\n",
    "\n",
    "vocabulary = [\"margherita\", \"pizza\", \"cheesecake\", \"truffle\", \"pasta\", \"reservation\", \"table\", \"open\", \"today\", \"address\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "61bbe411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: contractions in c:\\users\\user\\anaconda3\\envs\\chatbot\\lib\\site-packages (0.1.73)\n",
      "Requirement already satisfied: textsearch>=0.0.21 in c:\\users\\user\\anaconda3\\envs\\chatbot\\lib\\site-packages (from contractions) (0.0.24)\n",
      "Requirement already satisfied: anyascii in c:\\users\\user\\anaconda3\\envs\\chatbot\\lib\\site-packages (from textsearch>=0.0.21->contractions) (0.3.3)\n",
      "Requirement already satisfied: pyahocorasick in c:\\users\\user\\anaconda3\\envs\\chatbot\\lib\\site-packages (from textsearch>=0.0.21->contractions) (2.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install contractions\n",
    "import contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0b8009b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "sw = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d18ae8bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-Levenshtein in c:\\users\\user\\anaconda3\\envs\\chatbot\\lib\\site-packages (0.27.1)\n",
      "Requirement already satisfied: Levenshtein==0.27.1 in c:\\users\\user\\anaconda3\\envs\\chatbot\\lib\\site-packages (from python-Levenshtein) (0.27.1)\n",
      "Requirement already satisfied: rapidfuzz<4.0.0,>=3.9.0 in c:\\users\\user\\anaconda3\\envs\\chatbot\\lib\\site-packages (from Levenshtein==0.27.1->python-Levenshtein) (3.13.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install python-Levenshtein\n",
    "try:\n",
    "    import Levenshtein\n",
    "    has_lev = True\n",
    "except Exception:\n",
    "    has_lev = False\n",
    "# print(has_lev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e2e0f5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6c6bc1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Preprocessing\n",
    "cleaned_texts = []\n",
    "\n",
    "for text in texts:\n",
    "    # Step 1 - Remove contractions, strip and lowercase the text\n",
    "    contracted_text = contractions.fix(text)\n",
    "    stripped_txt = contracted_text.strip().lower()\n",
    "    \n",
    "    # Step 2 - Word tokenize (Add sentence tokenization in future)\n",
    "    tokens = nltk.word_tokenize(stripped_txt)\n",
    "    \n",
    "    # Step 3 - Remove special characters other than word, spaces and hyphen\n",
    "    temp_tokens = []\n",
    "    for t in tokens:\n",
    "        temp = re.sub(r\"[^\\w\\s-]\",\"\",t)\n",
    "        if temp.strip() != \"\":\n",
    "            temp_tokens.append(temp)\n",
    "    tokens = temp_tokens\n",
    "    \n",
    "    # Step 4 - Check if the text entered is correct using Levenshtein or difflib\n",
    "    corrected = []\n",
    "    for t in tokens:\n",
    "        if t in vocabulary:\n",
    "            corrected.append(t)\n",
    "            continue\n",
    "        \n",
    "        matched = None\n",
    "        if has_lev:\n",
    "            best = None\n",
    "            best_score = 0.0\n",
    "            for v in vocabulary:\n",
    "                score = Levenshtein.ratio(t, v)\n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best = v\n",
    "            if best_score >= 0.85:\n",
    "                matched = best\n",
    "                \n",
    "        else:\n",
    "            close = get_close_matches(t, vocabulary, n=1, cutoff=0.85)\n",
    "            if close:\n",
    "                matched = close[0]\n",
    "                \n",
    "        if matched:\n",
    "            corrected.append(matched)\n",
    "        else:\n",
    "            corrected.append(t)\n",
    "\n",
    "    tokens = corrected\n",
    "\n",
    "    # Step 5 - Remove stopwords\n",
    "    extra_stop = {\"please\", \"thanks\", \"thank\"}\n",
    "    temp_tokens2 = []\n",
    "    for t in tokens:\n",
    "        if t not in sw and t not in extra_stop:\n",
    "            temp_tokens2.append(t)\n",
    "    tokens = temp_tokens2\n",
    "    \n",
    "    # Step 6 - POS-aware lemmatization\n",
    "    lemm_tokens = []\n",
    "    pos_tags = nltk.pos_tag(tokens)\n",
    "    for word,tag in pos_tags:\n",
    "        wn_pos = get_wordnet_pos(tag)\n",
    "        lemma = lemmatizer.lemmatize(word,wn_pos)\n",
    "        lemm_tokens.append(lemma)\n",
    "    tokens = lemm_tokens\n",
    "\n",
    "    # Step 7 - Final cleanup and join\n",
    "    clean_tokens = []\n",
    "    for t in tokens:\n",
    "        if t and len(t.strip()) > 0:\n",
    "            clean_tokens.append(t)\n",
    "    cleaned = \" \".join(clean_tokens)\n",
    "    cleaned_texts.append(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9277ac8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw</th>\n",
       "      <th>cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi! Are you open today?</td>\n",
       "      <td>hi open today</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Do you have chesecake?</td>\n",
       "      <td>cheesecake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I don't want spicy food, do you have mild opti...</td>\n",
       "      <td>want spicy food mild option</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Can I reserve a table for 2 at 7pm?</td>\n",
       "      <td>reserve table 2 7pm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Is the trufle pasta available?</td>\n",
       "      <td>truffle pasta available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What's your addresses?</td>\n",
       "      <td>address</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I'm looking for pizzas and pastas.</td>\n",
       "      <td>look pizza pasta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The desserts were amazing yesterday!</td>\n",
       "      <td>dessert amaze yesterday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The customer is running late.</td>\n",
       "      <td>customer run late</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>We are better than the other restaurant.</td>\n",
       "      <td>well restaurant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 raw  \\\n",
       "0                         Hi! Are you open today?      \n",
       "1                             Do you have chesecake?   \n",
       "2  I don't want spicy food, do you have mild opti...   \n",
       "3                Can I reserve a table for 2 at 7pm?   \n",
       "4                     Is the trufle pasta available?   \n",
       "5                          What's your addresses?      \n",
       "6                 I'm looking for pizzas and pastas.   \n",
       "7               The desserts were amazing yesterday!   \n",
       "8                      The customer is running late.   \n",
       "9           We are better than the other restaurant.   \n",
       "\n",
       "                       cleaned  \n",
       "0                hi open today  \n",
       "1                   cheesecake  \n",
       "2  want spicy food mild option  \n",
       "3          reserve table 2 7pm  \n",
       "4      truffle pasta available  \n",
       "5                      address  \n",
       "6             look pizza pasta  \n",
       "7      dessert amaze yesterday  \n",
       "8            customer run late  \n",
       "9              well restaurant  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\"raw\": texts, \"cleaned\": cleaned_texts})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051c6695",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
